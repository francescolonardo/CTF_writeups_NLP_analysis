{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20376,"status":"ok","timestamp":1683293916758,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"yuC1-FvCapbN","outputId":"19d2de18-0b0e-48d9-ec07-6519a64292ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import pwd\n","username = pwd.getpwuid(os.getuid()).pw_name\n","home_path = f\"/home/{username}\"\n","os.chdir(os.path.join(home_path, \"GithubPythonCode/code\"))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683295688959,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"A3qF2gSVbRlS"},"outputs":[],"source":["model_type = \"roberta\"\n","pretrained_model = \"microsoft/codebert-base\"\n","\n","lang = \"python\"  # programming language\n","output_dir = f\"model/{lang}\"\n","\n","data_dir = \"../dataset\"\n","train_file = f\"{data_dir}/{lang}/train.jsonl\"\n","dev_file = f\"{data_dir}/{lang}/valid.jsonl\"\n","\n","source_length = 256\n","target_length = 128\n","\n","lr = 5e-5\n","beam_size = 10\n","batch_size = 256  # increased batch size for better GPU utilization\n","decay = 0.01\n","warmup = 500\n","epochs = 500"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17169157,"status":"ok","timestamp":1683312860233,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"gkREnv_lWwjA","outputId":"e0ee65ae-682a-4754-9db1-4a45a04fa91c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-05 14:08:14.061701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/05/2023 14:08:15 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/python', load_model_path=None, train_filename='../dataset/python/train.jsonl', dev_filename='../dataset/python/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=16, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=500, local_rank=-1, seed=42)\n","05/05/2023 14:08:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n","05/05/2023 14:08:20 - INFO - __main__ -   *** Example ***\n","05/05/2023 14:08:20 - INFO - __main__ -   idx: 0\n","05/05/2023 14:08:20 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_re', '_import', '_sys', '_from', '_set', 'upt', 'ools', '_import', '_setup', '_,', '_find', '_', 'packages', '_if', '_sys', '.', 'version', '_', 'info', '_[', '_0', '_]', '_<', '_3', '_:', '_raise', '_System', 'Exit', '_(', '_``', '_Error', '_:', '_blocks', 'at', '-', 'cli', '_requires', '_Python', '_3', \"_''\", '_)', '_sys', '.', 'exit', '_(', '_1', '_)', '_version', '_=', '_re', '.', 'search', '_(', '_r', \"'\", '^', '__', 'version', '__', '\\\\', 's', '_*', '_=', '\\\\', 's', '_*', \"_''\", '_(', '_.', '_*', '_)', \"_''\", \"_'\", '_,', '_open', '_(', \"_'\", 'blocks', 'at', 'cli', '/', 'main', '.', 'py', \"_'\", '_)', '_.', 'read', '_(', '_)', '_,', '_re', '.', 'M', '_)', '_.', 'group', '_(', '_1', '_)', '_long', '_', 'description', '_=', '_``', \"_''\", \"_''\", '_#', '_Block', 'stream', '_Satellite', '_CLI', '_A', '_command', '-', 'line', '_interface', '_for', '_config', 'uring', '_,', '_running', '_and', '_monitoring', '_a', '_Block', 'stream', '_Satellite', '_receiver', '_setup', '.', \"_''\", \"_''\", \"_''\", '_setup', '_(', '_name', '=', \"_''\", '_blocks', 'at', '-', 'cli', \"_''\", '_,', '_packages', '=', 'find', '_', 'packages', '_(', '_)', '_,', '_entry', '_', 'points', '=', '_{', '_``', '_console', '_', 'scripts', \"_''\", '_:', '_[', \"_'\", 'blocks', 'at', '-', 'cli', '_=', '_blocks', 'at', 'cli', '.', 'main', '_:', '_main', \"_'\", '_]', '_}', '_,', '_version', '=', 'version', '_,', '_description', '=', \"_''\", '_Block', 'stream', '_Satellite', '_CLI', \"_''\", '_,', '_long', '_', 'description', '=', 'long', '_', 'description', '_,', '_long', '_', 'description', '_', 'content', '_', 'type', \"='\", 'text', '/', 'mark', 'down', \"_'\", '_,', '_author', '=', \"_''\", '_Block', 'stream', '_Corp', \"_''\", '_,', '_author', '_', 'email', '=', \"_''\", '_satellite', '_@', '_block', 'stream', '.', 'com', \"_''\", '_,', '_url', '=', \"_''\", '_https', '_:', '_//', 'github', '.', 'com', '/', 'Block', 'stream', '/', 's', 'atellite', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   source_ids: 0 41975 769 6595 47427 31 278 29809 22890 6595 11808 2156 465 1215 48324 114 47427 4 21747 1215 23999 646 321 27779 28696 155 4832 1693 5149 46072 36 45518 37943 4832 5491 415 12 48556 3441 31886 155 12801 4839 47427 4 44054 36 112 4839 1732 5457 769 4 21061 36 910 108 35227 30529 21747 30529 37457 29 1009 5457 37457 29 1009 12801 36 479 1009 4839 12801 128 2156 490 36 128 30963 415 48556 73 17894 4 17163 128 4839 479 12745 36 4839 2156 769 4 448 4839 479 13839 36 112 4839 251 1215 42739 5457 45518 12801 12801 849 11700 8656 29801 45919 83 5936 12 1902 12332 13 40220 5206 2156 878 8 4872 10 11700 8656 29801 4797 11808 4 12801 12801 12801 11808 36 766 5214 12801 5491 415 12 48556 12801 2156 8368 5214 26559 1215 48324 36 4839 2156 3555 1215 21996 5214 25522 45518 12304 1215 45930 12801 4832 646 128 30963 415 12 48556 5457 5491 415 48556 4 17894 4832 1049 128 27779 35524 2156 1732 5214 21747 2156 8194 5214 12801 11700 8656 29801 45919 12801 2156 251 1215 42739 5214 3479 1215 42739 2156 251 1215 42739 1215 10166 1215 12528 47579 29015 73 6920 3955 128 2156 2730 5214 12801 11700 8656 1913 12801 2156 2730 1215 10555 5214 12801 7595 787 1803 8656 4 175 12801 2156 46471 5214 12801 1205 4832 21277 48340 4 175 73 38866 8656 73 29 43089 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_tokens: ['<s>', '``', '_``', \"_''\", '_This', '_code', '_snippet', '_sets', '_up', '_the', '_Block', 'stream', '_Satellite', '_CLI', '_package', '_for', '_installation', '_.', '_It', '_imports', '_the', '_necessary', '_modules', '_,', '_checks', '_that', '_the', '_Python', '_version', '_is', '_3', '_or', '_higher', '_,', '_and', '_sets', '_up', '_the', '_package', '_with', '_the', '_necessary', '_information', '_such', '_as', '_the', '_version', '_,', '_description', '_,', '_author', '_,', '_and', '_other', '_details', '_.', '_It', '_also', '_sets', '_up', '_the', '_entry', '_point', '_for', '_the', '_package', '_,', '_the', '_install', '_requirements', '_,', '_and', '_the', '_class', 'ifiers', '_for', '_the', '_package', '_.', \"_''\", \"_''\", \"_''\", '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   target_ids: 0 49519 45518 12801 152 3260 42772 3880 62 5 11700 8656 29801 45919 3737 13 8809 479 85 5058 5 2139 22744 2156 6240 14 5 31886 1732 16 155 50 723 2156 8 3880 62 5 3737 19 5 2139 335 215 25 5 1732 2156 8194 2156 2730 2156 8 97 1254 479 85 67 3880 62 5 3555 477 13 5 3737 2156 5 8486 3471 2156 8 5 1380 27368 13 5 3737 479 12801 12801 12801 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/05/2023 14:08:20 - INFO - __main__ -   *** Example ***\n","05/05/2023 14:08:20 - INFO - __main__ -   idx: 1\n","05/05/2023 14:08:20 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_torch', '_import', '_torch', '.', 'nn', '.', 'functional', '_as', '_F', '_import', '_torch', '.', 'nn', '_as', '_n', 'n', '_import', '_n', 'umpy', '_as', '_np', '_import', '_torch', '.', 'dist', 'ributed', '_as', '_dist', '_from', '_fun', 'ct', 'ools', '_import', '_partial', '_from', '_meg', 'atron', '_import', '_get', '_', 'args', '_,', '_get', '_', 'tim', 'ers', '_,', '_print', '_', 'rank', '_', '0', '_from', '_meg', 'atron', '.', 'core', '.', 'en', 'ums', '_import', '_Model', 'Type', '_from', '_meg', 'atron', '.', 'data', '.', 'v', 'it', '_', 'dat', 'as', 'et', '_import', '_build', '_', 'train', '_', 'valid', '_', 'dat', 'as', 'ets', '_from', '_meg', 'atron', '.', 'model', '.', 'vision', '.', 'd', 'ino', '_import', '_D', 'IN', 'OP', 'ret', 'rain', 'Model', '_from', '_meg', 'atron', '.', 'model', '.', 'vision', '.', 'kn', 'n', '_', 'monitor', '_import', '_kn', 'n', '_', 'p', 'redict', '_,', '_get', '_', 'feature', '_', 'bank', '_from', '_meg', 'atron', '.', 'training', '_import', '_pret', 'rain', '_from', '_meg', 'atron', '.', 'utils', '_import', '_average', '_', 'loss', 'es', '_', 'ac', 'ross', '_', 'data', '_', 'par', 'allel', '_', 'group', '_,', '_unw', 'rap', '_', 'model', '_from', '_torch', '.', 'nn', '.', 'par', 'allel', '.', 'dist', 'ributed', '_import', '_Dist', 'ributed', 'Data', 'Par', 'allel', '_as', '_torch', 'D', 'DP', '_from', '_meg', 'atron', '.', 'model', '_import', '_Dist', 'ributed', 'Data', 'Par', 'allel', '_as', '_Local', 'D', 'DP', '_from', '_meg', 'atron', '.', 'model', '_import', '_Float', '16', 'Module', '_def', '_model', '_', 'prov', 'ider', '_(', '_pre', '_', 'process', '=', 'True', '_,', '_post', '_', 'process', '=', 'True', '_)', '_:', '_``', \"_''\", \"_''\", '_Build', '_the', '_model', '_.', \"_''\", \"_''\", \"_''\", '_return', '_D', 'IN', 'OP', 'ret', 'rain', 'Model', '_(', '_pre', '_', 'process', '=', 'pre', '_', 'process', '_,', '_post', '_', 'process', '=', 'post', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   source_ids: 0 41975 24732 6595 24732 4 15688 4 38922 25 274 6595 24732 4 15688 25 295 282 6595 295 35187 25 46446 6595 24732 4 17165 18926 25 7018 31 1531 3894 22890 6595 9801 31 10721 44404 6595 120 1215 48204 2156 120 1215 10519 268 2156 5780 1215 40081 1215 288 31 10721 44404 4 7293 4 225 8014 6595 7192 40118 31 10721 44404 4 23687 4 705 405 1215 36146 281 594 6595 1119 1215 21714 1215 42679 1215 36146 281 2580 31 10721 44404 4 21818 4 14675 4 417 1696 6595 211 2444 5733 4903 9946 45149 31 10721 44404 4 21818 4 14675 4 15204 282 1215 38575 6595 11269 282 1215 642 39733 2156 120 1215 44565 1215 5760 31 10721 44404 4 32530 6595 11857 9946 31 10721 44404 4 49320 6595 674 1215 13242 293 1215 1043 14500 1215 23687 1215 5489 44682 1215 13839 2156 10963 8645 1215 21818 31 24732 4 15688 4 5489 44682 4 17165 18926 6595 11281 18926 30383 22011 44682 25 24732 495 5174 31 10721 44404 4 21818 6595 11281 18926 30383 22011 44682 25 4004 495 5174 31 10721 44404 4 21818 6595 43944 1549 48720 3816 1421 1215 13138 5326 36 1198 1215 31931 5214 36948 2156 618 1215 31931 5214 36948 4839 4832 45518 12801 12801 15195 5 1421 479 12801 12801 12801 671 211 2444 5733 4903 9946 45149 36 1198 1215 31931 5214 5234 1215 31931 2156 618 1215 31931 5214 7049 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_tokens: ['<s>', 'This', '_code', '_snippet', '_implements', '_a', '_training', '_loop', '_for', '_a', '_vision', '_model', '_using', '_the', '_Meg', 'atron', '_framework', '_.', '_It', '_builds', '_the', '_model', '_,', '_datasets', '_,', '_and', '_batch', '_,', '_and', '_then', '_runs', '_a', '_forward', '_step', '_with', '_the', '_model', '_,', '_passing', '_in', '_the', '_batch', '_and', '_a', '_loss', '_function', '_.', '_It', '_also', '_calculates', '_the', '_accuracy', '_of', '_the', '_model', \"_'\", 's', '_predictions', '_using', '_the', '_K', '-', 'Ne', 'arest', '_Neighbor', '_algorithm', '_.', '_Finally', '_,', '_it', '_runs', '_the', '_pret', 'rain', '_function', '_to', '_start', '_the', '_training', '_loop', '_.', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   target_ids: 0 713 3260 42772 36987 10 1058 14018 13 10 3360 1421 634 5 14938 44404 7208 479 85 12095 5 1421 2156 42532 2156 8 14398 2156 8 172 1237 10 556 1149 19 5 1421 2156 3133 11 5 14398 8 10 872 5043 479 85 67 38570 5 8611 9 5 1421 128 29 12535 634 5 229 12 14563 18759 36968 17194 479 3347 2156 24 1237 5 11857 9946 5043 7 386 5 1058 14018 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/05/2023 14:08:20 - INFO - __main__ -   *** Example ***\n","05/05/2023 14:08:20 - INFO - __main__ -   idx: 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_sys', '_import', '_os', '_import', '_shut', 'il', '_import', '_codec', 's', '_from', '_dist', 'utils', '.', 'core', '_import', '_Command', '_from', '_dist', 'utils', '.', 'command', '.', 'clean', '_import', '_clean', '_as', '_Clean', '_import', '_package', '_AB', 'SP', 'ATH', '_', 'RO', 'OT', 'DIR', '_=', '_os', '.', 'path', '.', 'dir', 'name', '_(', '_os', '.', 'path', '.', 'ab', 'sp', 'ath', '_(', '___', 'file', '__', '_)', '_)', '_REL', 'PATH', '_', 'FIL', 'ES', '_', 'CLE', 'AN', '_=', '_[', \"_'\", 'build', \"_'\", '_,', \"_'\", 'dist', \"_'\", '_,', \"_'\", '_{', '_name', '_}', '_.', 'egg', '-', 'info', \"'.\", 'format', '_(', '_name', '_=', '_package', '.', 'name', '_)', '_,', \"_'.\", 'cache', \"_'\", '_]', '_REL', 'PATH', '_', 'W', 'ALK', '_', 'FIL', 'ES', '_', 'EXT', '_', 'CLE', 'AN', '_=', '_[', \"_'.\", 'py', 'c', \"_'\", '_]', '_REL', 'PATH', '_', 'W', 'ALK', '_', 'DIR', 'S', '_', 'CLE', 'AN', '_=', '_[', \"_'\", '__', 'py', 'cache', '__', \"_'\", '_]', '_class', '_Clean', 'Command', '_(', '_Clean', '_)', '_:', '_def', '_run', '_(', '_self', '_)', '_:', '_Clean', '.', 'run', '_(', '_self', '_)', '_for', '_filename', '_in', '_REL', 'PATH', '_', 'FIL', 'ES', '_', 'CLE', 'AN', '_:', '_if', '_os', '.', 'path', '.', 'ex', 'ists', '_(', '_filename', '_)', '_:', '_shut', 'il', '.', 'r', 'mt', 'ree', '_(', '_filename', '_)', '_for', '_dir', 'path', '_,', '_dir', 'names', '_,', '_fil', 'en', 'ames', '_in', '_os', '.', 'walk', '_(', '_AB', 'SP', 'ATH', '_', 'RO', 'OT', 'DIR', '_)', '_:', '_for', '_filename', '_in', '_fil', 'en', 'ames', '_:', '_for', '_extension', '_in', '_REL', 'PATH', '_', 'W', 'ALK', '_', 'FIL', 'ES', '_', 'EXT', '_', 'CLE', 'AN', '_:', '_if', '_filename', '.', 'end', 'sw', 'ith', '_(', '_extension', '_)', '_:', '_path', '_=', '_os', '.', 'path', '.', 'join', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   source_ids: 0 41975 47427 6595 11988 6595 2572 718 6595 45797 29 31 7018 49320 4 7293 6595 9539 31 7018 49320 4 41483 4 28401 6595 2382 25 10326 6595 3737 6266 4186 18267 1215 8727 3293 47992 5457 11988 4 22609 4 41292 13650 36 11988 4 22609 4 873 4182 2681 36 27148 21710 30529 4839 4839 5698 48468 1215 46008 1723 1215 21631 1889 5457 646 128 23411 128 2156 128 17165 128 2156 128 25522 766 35524 479 38299 12 23999 2652 34609 36 766 5457 3737 4 13650 4839 2156 48694 47974 128 27779 5698 48468 1215 771 23284 1215 46008 1723 1215 42680 1215 21631 1889 5457 646 48694 17163 438 128 27779 5698 48468 1215 771 23284 1215 47992 104 1215 21631 1889 5457 646 128 30529 17163 47974 30529 128 27779 1380 10326 46785 36 10326 4839 4832 3816 422 36 1403 4839 4832 10326 4 2962 36 1403 4839 13 48786 11 5698 48468 1215 46008 1723 1215 21631 1889 4832 114 11988 4 22609 4 3463 1952 36 48786 4839 4832 2572 718 4 338 16100 5314 36 48786 4839 13 19855 22609 2156 19855 37815 2156 14242 225 12336 11 11988 4 10097 36 6266 4186 18267 1215 8727 3293 47992 4839 4832 13 48786 11 14242 225 12336 4832 13 5064 11 5698 48468 1215 771 23284 1215 46008 1723 1215 42680 1215 21631 1889 4832 114 48786 4 1397 4184 3432 36 5064 4839 4832 2718 5457 11988 4 22609 4 26960 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_tokens: ['<s>', 'This', '_code', '_snippet', '_provides', '_a', '_set', '_of', '_commands', '_and', '_functions', '_used', '_to', '_clean', '_,', '_test', '_,', '_and', '_install', '_a', '_Python', '_package', '_.', '_The', '_Clean', 'Command', '_class', '_removes', '_build', '_,', '_dist', '_,', '_egg', '-', 'info', '_,', '_and', '_cache', '_files', '_,', '_as', '_well', '_as', '_any', '_files', '_with', '_a', '_specified', '_extension', '_and', '_directories', '_with', '_a', '_specified', '_name', '_.', '_The', '_Test', 'Command', '_class', '_runs', '_py', 'test', '_with', '_any', '_given', '_arguments', '_.', '_The', '_get', '_', 'long', '_', 'description', '_(', '_)', '_function', '_reads', '_in', '_a', '_list', '_of', '_file', 'path', 's', '_and', '_returns', '_the', '_content', '_of', '_the', '_files', '_as', '_a', '_single', '_string', '_.', '_Finally', '_,', '_the', '_main', '_(', '_)', '_function', '_uses', '_set', 'upt', 'ools', '_or', '_dist', 'utils', '_to', '_install', '_the', '_package', '_with', '_the', '_given', '_metadata', '_.', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   target_ids: 0 713 3260 42772 1639 10 278 9 16388 8 8047 341 7 2382 2156 1296 2156 8 8486 10 31886 3737 479 20 10326 46785 1380 24508 1119 2156 7018 2156 8380 12 23999 2156 8 30283 6773 2156 25 157 25 143 6773 19 10 17966 5064 8 44472 19 10 17966 766 479 20 4500 46785 1380 1237 19290 21959 19 143 576 7576 479 20 120 1215 3479 1215 42739 36 4839 5043 7005 11 10 889 9 2870 22609 29 8 2886 5 1383 9 5 6773 25 10 881 6755 479 3347 2156 5 1049 36 4839 5043 2939 278 29809 22890 50 7018 49320 7 8486 5 3737 19 5 576 39535 479 2 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n","05/05/2023 14:08:20 - INFO - __main__ -   *** Example ***\n","05/05/2023 14:08:20 - INFO - __main__ -   idx: 3\n","05/05/2023 14:08:20 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_tens', 'or', 'flow', '_as', '_tf', '_FL', 'AG', 'S', '_=', '_tf', '.', 'app', '.', 'flags', '.', 'FLAG', 'S', '_def', '_setup', '_', 'input', 's', '_(', '_s', 'ess', '_,', '_fil', 'en', 'ames', '_,', '_image', '_', 'size', '=', 'None', '_,', '_capacity', '_', 'factor', '=', '3', '_)', '_:', '_if', '_image', '_', 'size', '_is', '_None', '_:', '_image', '_', 'size', '_=', '_FL', 'AG', 'S', '.', 'sample', '_', 'size', '_reader', '_=', '_tf', '.', 'Wh', 'ole', 'File', 'Reader', '_(', '_)', '_filename', '_', 'queue', '_=', '_tf', '.', 'train', '.', 'string', '_', 'input', '_', 'produ', 'cer', '_(', '_fil', 'en', 'ames', '_)', '_key', '_,', '_value', '_=', '_reader', '.', 'read', '_(', '_filename', '_', 'queue', '_)', '_channels', '_=', '_3', '_image', '_=', '_tf', '.', 'image', '.', 'dec', 'ode', '_', 'j', 'peg', '_(', '_value', '_,', '_channels', '=', 'ch', 'annels', '_,', '_name', '=', \"_''\", '_dataset', '_', 'image', \"_''\", '_)', '_image', '.', 'set', '_', 'shape', '_(', '_[', '_None', '_,', '_None', '_,', '_channels', '_]', '_)', '_image', '_=', '_tf', '.', 'image', '.', 'random', '_', 'fl', 'ip', '_', 'left', '_', 'right', '_(', '_image', '_)', '_image', '_=', '_tf', '.', 'image', '.', 'random', '_', 's', 'aturation', '_(', '_image', '_,', '_.', '95', '_,', '_1', '.', '05', '_)', '_image', '_=', '_tf', '.', 'image', '.', 'random', '_', 'bright', 'ness', '_(', '_image', '_,', '_.', '05', '_)', '_image', '_=', '_tf', '.', 'image', '.', 'random', '_', 'cont', 'rast', '_(', '_image', '_,', '_.', '95', '_,', '_1', '.', '05', '_)', '_w', 'iggle', '_=', '_8', '_off', '_', 'x', '_,', '_off', '_', 'y', '_=', '_25', '-', 'w', 'iggle', '_,', '_60', '-', 'w', 'iggle', '_crop', '_', 'size', '_=', '_128', '_crop', '_', 'size', '_', 'plus', '_=', '_crop', '_', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   source_ids: 0 41975 7281 368 19322 25 47724 8854 3450 104 5457 47724 4 3340 4 46760 4 46435 104 3816 11808 1215 46797 29 36 579 3361 2156 14242 225 12336 2156 2274 1215 10799 5214 29802 2156 2148 1215 31192 5214 246 4839 4832 114 2274 1215 10799 16 9291 4832 2274 1215 10799 5457 8854 3450 104 4 14029 1215 10799 10746 5457 47724 4 14447 4104 9966 46347 36 4839 48786 1215 48702 5457 47724 4 21714 4 20951 1215 46797 1215 26790 7742 36 14242 225 12336 4839 762 2156 923 5457 10746 4 12745 36 48786 1215 48702 4839 6237 5457 155 2274 5457 47724 4 20094 4 11127 4636 1215 267 41191 36 923 2156 6237 5214 611 34735 2156 766 5214 12801 41616 1215 20094 12801 4839 2274 4 8738 1215 43882 36 646 9291 2156 9291 2156 6237 27779 4839 2274 5457 47724 4 20094 4 45041 1215 4825 1588 1215 6960 1215 4070 36 2274 4839 2274 5457 47724 4 20094 4 45041 1215 29 41628 36 2274 2156 479 4015 2156 112 4 2546 4839 2274 5457 47724 4 20094 4 45041 1215 23471 1825 36 2274 2156 479 2546 4839 2274 5457 47724 4 20094 4 45041 1215 10800 16136 36 2274 2156 479 4015 2156 112 4 2546 4839 885 24217 5457 290 160 1215 1178 2156 160 1215 219 5457 564 12 605 24217 2156 1191 12 605 24217 6792 1215 10799 5457 13950 6792 1215 10799 1215 7269 5457 6792 1215 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_tokens: ['<s>', 'This', '_code', '_snippet', '_sets', '_up', '_inputs', '_for', '_a', '_T', 'ensor', 'flow', '_session', '_.', '_It', '_reads', '_in', '_a', '_list', '_of', '_fil', 'en', 'ames', '_,', '_then', '_reads', '_the', '_files', '_and', '_dec', 'odes', '_them', '_as', '_JPEG', 's', '_.', '_It', '_then', '_applies', '_random', '_flips', '_,', '_saturation', '_,', '_brightness', '_,', '_and', '_contrast', '_to', '_the', '_images', '_,', '_crops', '_them', '_to', '_a', '_bound', 'ing', '_box', '_,', '_and', '_res', 'izes', '_them', '_to', '_a', '_given', '_image', '_size', '_.', '_Finally', '_,', '_it', '_creates', '_batches', '_of', '_features', '_and', '_labels', '_and', '_starts', '_the', '_queue', '_runners', '_for', '_the', '_session', '_.', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   target_ids: 0 713 3260 42772 3880 62 16584 13 10 255 35354 19322 1852 479 85 7005 11 10 889 9 14242 225 12336 2156 172 7005 5 6773 8 5044 19160 106 25 45258 29 479 85 172 11459 9624 37719 2156 39109 2156 27406 2156 8 5709 7 5 3156 2156 9774 106 7 10 8191 154 2233 2156 8 5032 7396 106 7 10 576 2274 1836 479 3347 2156 24 6670 34183 9 1575 8 14105 8 2012 5 21021 8437 13 5 1852 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/05/2023 14:08:20 - INFO - __main__ -   *** Example ***\n","05/05/2023 14:08:20 - INFO - __main__ -   idx: 4\n","05/05/2023 14:08:20 - INFO - __main__ -   source_tokens: ['<s>', 'import', '_torch', '_from', '_torch', 'vision', '.', 'models', '.', 'res', 'net', '_import', '_res', 'net', '50', '_as', '__', 'res', 'net', '50', '_from', '_src', '.', 'res', 'net', '50', '_import', '_res', 'net', '50', 'w', '2', '_as', '__', 'res', 'net', '50', 'w', '2', '_from', '_src', '.', 'res', 'net', '50', '_import', '_res', 'net', '50', 'w', '4', '_as', '__', 'res', 'net', '50', 'w', '4', '_from', '_src', '.', 'res', 'net', '50', '_import', '_res', 'net', '50', 'w', '5', '_as', '__', 'res', 'net', '50', 'w', '5', '_dependencies', '_=', '_[', '_``', '_torch', \"_''\", '_,', '_``', '_torch', 'vision', \"_''\", '_]', '_def', '_res', 'net', '50', '_(', '_pret', 'rained', '=', 'True', '_,', '_*', '_*', '_k', 'w', 'args', '_)', '_:', '_``', \"_''\", \"_''\", '_Res', 'Net', '-', '50', '_pre', '-', 'trained', '_with', '_Sw', 'AV', '_.', '_Note', '_that', '_`', '_f', 'c', '.', 'weight', '_`', '_and', '_`', '_f', 'c', '.', 'b', 'ias', '_`', '_are', '_randomly', '_initialized', '_.', '_A', 'chie', 'ves', '_75', '.', '3', '_%', '_top', '-', '1', '_accuracy', '_on', '_Image', 'Net', '_when', '_`', '_f', 'c', '_`', '_is', '_trained', '.', '_``', \"_''\", \"_''\", '_model', '_=', '__', 'res', 'net', '50', '_(', '_pret', 'rained', '=', 'False', '_,', '_*', '_*', '_k', 'w', 'args', '_)', '_if', '_pret', 'rained', '_:', '_state', '_', 'dict', '_=', '_torch', '.', 'hub', '.', 'load', '_', 'state', '_', 'dict', '_', 'from', '_', 'url', '_(', '_url', '=', \"_''\", '_https', '_:', '_//', 'dl', '.', 'f', 'ba', 'ip', 'ublic', 'files', '.', 'com', '/', 'deep', 'cl', 'uster', '/', 'sw', 'av', '_', '800', 'ep', '_', 'pret', 'rain', '.', 'p', 'th', '.', 'tar', \"_''\", '_,', '_map', '_', 'location', '=', \"_''\", '_cpu', \"_''\", '_,', '_)', '_state', '_', 'dict', '_=', '_{', '_k', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   source_ids: 0 41975 24732 31 24732 14675 4 43457 4 1535 4135 6595 5032 4135 1096 25 18134 1535 4135 1096 31 47215 4 1535 4135 1096 6595 5032 4135 1096 605 176 25 18134 1535 4135 1096 605 176 31 47215 4 1535 4135 1096 6595 5032 4135 1096 605 306 25 18134 1535 4135 1096 605 306 31 47215 4 1535 4135 1096 6595 5032 4135 1096 605 245 25 18134 1535 4135 1096 605 245 45371 5457 646 45518 24732 12801 2156 45518 24732 14675 12801 27779 3816 5032 4135 1096 36 11857 26492 5214 36948 2156 1009 1009 449 605 48204 4839 4832 45518 12801 12801 4787 15721 12 1096 1198 12 23830 19 3323 10612 479 6068 14 22209 856 438 4 4301 22209 8 22209 856 438 4 428 5003 22209 32 22422 49271 479 83 17309 3677 3337 4 246 7606 299 12 134 8611 15 2960 15721 77 22209 856 438 22209 16 5389 4 45518 12801 12801 1421 5457 18134 1535 4135 1096 36 11857 26492 5214 46659 2156 1009 1009 449 605 48204 4839 114 11857 26492 4832 194 1215 25867 5457 24732 4 31002 4 16204 1215 4897 1215 25867 1215 7761 1215 6423 36 46471 5214 12801 1205 4832 21277 30469 4 506 3178 1588 40171 42018 4 175 73 13637 3998 10504 73 4184 1469 1215 3913 2462 1215 42354 9946 4 642 212 4 11404 12801 2156 5456 1215 41829 5214 12801 49357 12801 2156 4839 194 1215 25867 5457 25522 449 2\n","05/05/2023 14:08:20 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_tokens: ['<s>', 'This', '_code', '_snippet', '_provides', '_a', '_set', '_of', '_functions', '_for', '_loading', '_pre', '-', 'trained', '_Res', 'Net', '-', '50', '_models', '_with', '_Sw', 'AV', '_.', '_The', '_functions', '_allow', '_for', '_loading', '_the', '_original', '_Res', 'Net', '-', '50', '_model', '_,', '_as', '_well', '_as', '_Res', 'Net', '-', '50', '-', 'w', '2', '_,', '_Res', 'Net', '-', '50', '-', 'w', '4', '_,', '_and', '_Res', 'Net', '-', '50', '-', 'w', '5', '_models', '_.', '_The', '_functions', '_are', '_designed', '_to', '_load', '_the', '_pre', '-', 'trained', '_weights', '_from', '_the', '_specified', '_URLs', '_and', '_return', '_the', '_models', '_with', '_the', '_weights', '_loaded', '_.', '</s>']\n","05/05/2023 14:08:20 - INFO - __main__ -   target_ids: 0 713 3260 42772 1639 10 278 9 8047 13 16761 1198 12 23830 4787 15721 12 1096 3092 19 3323 10612 479 20 8047 1157 13 16761 5 1461 4787 15721 12 1096 1421 2156 25 157 25 4787 15721 12 1096 12 605 176 2156 4787 15721 12 1096 12 605 306 2156 8 4787 15721 12 1096 12 605 245 3092 479 20 8047 32 1887 7 7511 5 1198 12 23830 23341 31 5 17966 44163 8 671 5 3092 19 5 23341 7973 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","05/05/2023 14:08:20 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","05/05/2023 14:08:21 - INFO - __main__ -   ***** Running training *****\n","05/05/2023 14:08:21 - INFO - __main__ -     Num examples = 700\n","05/05/2023 14:08:21 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:08:21 - INFO - __main__ -     Num epoch = 50\n","epoch 0 loss 9.2651: 100% 44/44 [00:45<00:00,  1.03s/it]\n","05/05/2023 14:09:07 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:09:07 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:09:07 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:09:10 - INFO - __main__ -     eval_ppl = 888.14022\n","05/05/2023 14:09:10 - INFO - __main__ -     global_step = 45\n","05/05/2023 14:09:10 - INFO - __main__ -     train_loss = 9.2651\n","05/05/2023 14:09:10 - INFO - __main__ -     ********************\n","05/05/2023 14:09:12 - INFO - __main__ -     Best ppl:888.14022\n","05/05/2023 14:09:12 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:19:44 - INFO - __main__ -     bleu-4 = 2.61 \n","05/05/2023 14:19:44 - INFO - __main__ -     ********************\n","05/05/2023 14:19:44 - INFO - __main__ -     Best bleu:2.61\n","05/05/2023 14:19:44 - INFO - __main__ -     ********************\n","epoch 1 loss 6.2444: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:20:34 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:20:34 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:20:34 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:20:37 - INFO - __main__ -     eval_ppl = 329.42126\n","05/05/2023 14:20:37 - INFO - __main__ -     global_step = 89\n","05/05/2023 14:20:37 - INFO - __main__ -     train_loss = 6.2444\n","05/05/2023 14:20:37 - INFO - __main__ -     ********************\n","05/05/2023 14:20:39 - INFO - __main__ -     Best ppl:329.42126\n","05/05/2023 14:20:39 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:31:13 - INFO - __main__ -     bleu-4 = 3.87 \n","05/05/2023 14:31:13 - INFO - __main__ -     ********************\n","05/05/2023 14:31:13 - INFO - __main__ -     Best bleu:3.87\n","05/05/2023 14:31:13 - INFO - __main__ -     ********************\n","epoch 2 loss 5.3127: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:32:03 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:32:03 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:32:03 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:32:06 - INFO - __main__ -     eval_ppl = 133.31806\n","05/05/2023 14:32:06 - INFO - __main__ -     global_step = 133\n","05/05/2023 14:32:06 - INFO - __main__ -     train_loss = 5.3127\n","05/05/2023 14:32:06 - INFO - __main__ -     ********************\n","05/05/2023 14:32:08 - INFO - __main__ -     Best ppl:133.31806\n","05/05/2023 14:32:08 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:39:56 - INFO - __main__ -     bleu-4 = 17.21 \n","05/05/2023 14:39:56 - INFO - __main__ -     ********************\n","05/05/2023 14:39:56 - INFO - __main__ -     Best bleu:17.21\n","05/05/2023 14:39:56 - INFO - __main__ -     ********************\n","epoch 3 loss 4.5182: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:40:45 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:40:45 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:40:45 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:40:49 - INFO - __main__ -     eval_ppl = 78.09\n","05/05/2023 14:40:49 - INFO - __main__ -     global_step = 177\n","05/05/2023 14:40:49 - INFO - __main__ -     train_loss = 4.5182\n","05/05/2023 14:40:49 - INFO - __main__ -     ********************\n","05/05/2023 14:40:51 - INFO - __main__ -     Best ppl:78.09\n","05/05/2023 14:40:51 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:44:23 - INFO - __main__ -     bleu-4 = 18.37 \n","05/05/2023 14:44:23 - INFO - __main__ -     ********************\n","05/05/2023 14:44:23 - INFO - __main__ -     Best bleu:18.37\n","05/05/2023 14:44:23 - INFO - __main__ -     ********************\n","epoch 4 loss 4.0221: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:45:13 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:45:13 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:45:13 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:45:16 - INFO - __main__ -     eval_ppl = 55.73682\n","05/05/2023 14:45:16 - INFO - __main__ -     global_step = 221\n","05/05/2023 14:45:16 - INFO - __main__ -     train_loss = 4.0221\n","05/05/2023 14:45:16 - INFO - __main__ -     ********************\n","05/05/2023 14:45:18 - INFO - __main__ -     Best ppl:55.73682\n","05/05/2023 14:45:18 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:48:31 - INFO - __main__ -     bleu-4 = 15.02 \n","05/05/2023 14:48:31 - INFO - __main__ -     ********************\n","epoch 5 loss 3.6596: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:49:19 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:49:19 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:49:19 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:49:22 - INFO - __main__ -     eval_ppl = 46.92233\n","05/05/2023 14:49:22 - INFO - __main__ -     global_step = 265\n","05/05/2023 14:49:22 - INFO - __main__ -     train_loss = 3.6596\n","05/05/2023 14:49:22 - INFO - __main__ -     ********************\n","05/05/2023 14:49:24 - INFO - __main__ -     Best ppl:46.92233\n","05/05/2023 14:49:24 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:52:47 - INFO - __main__ -     bleu-4 = 18.42 \n","05/05/2023 14:52:47 - INFO - __main__ -     ********************\n","05/05/2023 14:52:47 - INFO - __main__ -     Best bleu:18.42\n","05/05/2023 14:52:47 - INFO - __main__ -     ********************\n","epoch 6 loss 3.3873: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:53:37 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:53:37 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:53:37 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:53:40 - INFO - __main__ -     eval_ppl = 41.81229\n","05/05/2023 14:53:40 - INFO - __main__ -     global_step = 309\n","05/05/2023 14:53:40 - INFO - __main__ -     train_loss = 3.3873\n","05/05/2023 14:53:40 - INFO - __main__ -     ********************\n","05/05/2023 14:53:43 - INFO - __main__ -     Best ppl:41.81229\n","05/05/2023 14:53:43 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 14:58:12 - INFO - __main__ -     bleu-4 = 16.62 \n","05/05/2023 14:58:12 - INFO - __main__ -     ********************\n","epoch 7 loss 3.1637: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 14:58:59 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 14:58:59 - INFO - __main__ -     Num examples = 150\n","05/05/2023 14:58:59 - INFO - __main__ -     Batch size = 16\n","05/05/2023 14:59:03 - INFO - __main__ -     eval_ppl = 38.08113\n","05/05/2023 14:59:03 - INFO - __main__ -     global_step = 353\n","05/05/2023 14:59:03 - INFO - __main__ -     train_loss = 3.1637\n","05/05/2023 14:59:03 - INFO - __main__ -     ********************\n","05/05/2023 14:59:05 - INFO - __main__ -     Best ppl:38.08113\n","05/05/2023 14:59:05 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:03:57 - INFO - __main__ -     bleu-4 = 18.14 \n","05/05/2023 15:03:57 - INFO - __main__ -     ********************\n","epoch 8 loss 2.9662: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:04:44 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:04:44 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:04:44 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:04:47 - INFO - __main__ -     eval_ppl = 35.88224\n","05/05/2023 15:04:47 - INFO - __main__ -     global_step = 397\n","05/05/2023 15:04:47 - INFO - __main__ -     train_loss = 2.9662\n","05/05/2023 15:04:47 - INFO - __main__ -     ********************\n","05/05/2023 15:04:50 - INFO - __main__ -     Best ppl:35.88224\n","05/05/2023 15:04:50 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:08:56 - INFO - __main__ -     bleu-4 = 18.93 \n","05/05/2023 15:08:56 - INFO - __main__ -     ********************\n","05/05/2023 15:08:56 - INFO - __main__ -     Best bleu:18.93\n","05/05/2023 15:08:56 - INFO - __main__ -     ********************\n","epoch 9 loss 2.7928: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:09:45 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:09:45 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:09:45 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:09:49 - INFO - __main__ -     eval_ppl = 33.65303\n","05/05/2023 15:09:49 - INFO - __main__ -     global_step = 441\n","05/05/2023 15:09:49 - INFO - __main__ -     train_loss = 2.7928\n","05/05/2023 15:09:49 - INFO - __main__ -     ********************\n","05/05/2023 15:09:51 - INFO - __main__ -     Best ppl:33.65303\n","05/05/2023 15:09:51 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:13:23 - INFO - __main__ -     bleu-4 = 21.52 \n","05/05/2023 15:13:23 - INFO - __main__ -     ********************\n","05/05/2023 15:13:23 - INFO - __main__ -     Best bleu:21.52\n","05/05/2023 15:13:23 - INFO - __main__ -     ********************\n","epoch 10 loss 2.6349: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:14:12 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:14:12 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:14:12 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:14:15 - INFO - __main__ -     eval_ppl = 32.38935\n","05/05/2023 15:14:15 - INFO - __main__ -     global_step = 485\n","05/05/2023 15:14:15 - INFO - __main__ -     train_loss = 2.6349\n","05/05/2023 15:14:15 - INFO - __main__ -     ********************\n","05/05/2023 15:14:18 - INFO - __main__ -     Best ppl:32.38935\n","05/05/2023 15:14:18 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:18:46 - INFO - __main__ -     bleu-4 = 23.12 \n","05/05/2023 15:18:46 - INFO - __main__ -     ********************\n","05/05/2023 15:18:46 - INFO - __main__ -     Best bleu:23.12\n","05/05/2023 15:18:46 - INFO - __main__ -     ********************\n","epoch 11 loss 2.487: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:19:35 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:19:35 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:19:35 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:19:39 - INFO - __main__ -     eval_ppl = 30.76594\n","05/05/2023 15:19:39 - INFO - __main__ -     global_step = 529\n","05/05/2023 15:19:39 - INFO - __main__ -     train_loss = 2.487\n","05/05/2023 15:19:39 - INFO - __main__ -     ********************\n","05/05/2023 15:19:42 - INFO - __main__ -     Best ppl:30.76594\n","05/05/2023 15:19:42 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:23:54 - INFO - __main__ -     bleu-4 = 18.61 \n","05/05/2023 15:23:54 - INFO - __main__ -     ********************\n","epoch 12 loss 2.3498: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:24:41 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:24:41 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:24:41 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:24:44 - INFO - __main__ -     eval_ppl = 29.81243\n","05/05/2023 15:24:44 - INFO - __main__ -     global_step = 573\n","05/05/2023 15:24:44 - INFO - __main__ -     train_loss = 2.3498\n","05/05/2023 15:24:44 - INFO - __main__ -     ********************\n","05/05/2023 15:24:47 - INFO - __main__ -     Best ppl:29.81243\n","05/05/2023 15:24:47 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:29:38 - INFO - __main__ -     bleu-4 = 24.05 \n","05/05/2023 15:29:38 - INFO - __main__ -     ********************\n","05/05/2023 15:29:38 - INFO - __main__ -     Best bleu:24.05\n","05/05/2023 15:29:38 - INFO - __main__ -     ********************\n","epoch 13 loss 2.2265: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:30:29 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:30:29 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:30:29 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:30:32 - INFO - __main__ -     eval_ppl = 29.43671\n","05/05/2023 15:30:32 - INFO - __main__ -     global_step = 617\n","05/05/2023 15:30:32 - INFO - __main__ -     train_loss = 2.2265\n","05/05/2023 15:30:32 - INFO - __main__ -     ********************\n","05/05/2023 15:30:34 - INFO - __main__ -     Best ppl:29.43671\n","05/05/2023 15:30:34 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:34:51 - INFO - __main__ -     bleu-4 = 22.28 \n","05/05/2023 15:34:51 - INFO - __main__ -     ********************\n","epoch 14 loss 2.108: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:35:39 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:35:39 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:35:39 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:35:42 - INFO - __main__ -     eval_ppl = 28.59021\n","05/05/2023 15:35:42 - INFO - __main__ -     global_step = 661\n","05/05/2023 15:35:42 - INFO - __main__ -     train_loss = 2.108\n","05/05/2023 15:35:42 - INFO - __main__ -     ********************\n","05/05/2023 15:35:45 - INFO - __main__ -     Best ppl:28.59021\n","05/05/2023 15:35:45 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:40:23 - INFO - __main__ -     bleu-4 = 23.64 \n","05/05/2023 15:40:23 - INFO - __main__ -     ********************\n","epoch 15 loss 2.0027: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:41:11 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:41:11 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:41:11 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:41:14 - INFO - __main__ -     eval_ppl = 28.24701\n","05/05/2023 15:41:14 - INFO - __main__ -     global_step = 705\n","05/05/2023 15:41:14 - INFO - __main__ -     train_loss = 2.0027\n","05/05/2023 15:41:14 - INFO - __main__ -     ********************\n","05/05/2023 15:41:16 - INFO - __main__ -     Best ppl:28.24701\n","05/05/2023 15:41:16 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:45:59 - INFO - __main__ -     bleu-4 = 23.56 \n","05/05/2023 15:45:59 - INFO - __main__ -     ********************\n","epoch 16 loss 1.9046: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:46:47 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:46:47 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:46:47 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:46:50 - INFO - __main__ -     eval_ppl = 28.44529\n","05/05/2023 15:46:50 - INFO - __main__ -     global_step = 749\n","05/05/2023 15:46:50 - INFO - __main__ -     train_loss = 1.9046\n","05/05/2023 15:46:50 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:52:01 - INFO - __main__ -     bleu-4 = 23.92 \n","05/05/2023 15:52:01 - INFO - __main__ -     ********************\n","epoch 17 loss 1.8082: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:52:48 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:52:48 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:52:48 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:52:52 - INFO - __main__ -     eval_ppl = 28.60642\n","05/05/2023 15:52:52 - INFO - __main__ -     global_step = 793\n","05/05/2023 15:52:52 - INFO - __main__ -     train_loss = 1.8082\n","05/05/2023 15:52:52 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 15:57:42 - INFO - __main__ -     bleu-4 = 23.25 \n","05/05/2023 15:57:42 - INFO - __main__ -     ********************\n","epoch 18 loss 1.7224: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 15:58:29 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 15:58:29 - INFO - __main__ -     Num examples = 150\n","05/05/2023 15:58:29 - INFO - __main__ -     Batch size = 16\n","05/05/2023 15:58:33 - INFO - __main__ -     eval_ppl = 28.01365\n","05/05/2023 15:58:33 - INFO - __main__ -     global_step = 837\n","05/05/2023 15:58:33 - INFO - __main__ -     train_loss = 1.7224\n","05/05/2023 15:58:33 - INFO - __main__ -     ********************\n","05/05/2023 15:58:36 - INFO - __main__ -     Best ppl:28.01365\n","05/05/2023 15:58:36 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:03:07 - INFO - __main__ -     bleu-4 = 24.44 \n","05/05/2023 16:03:07 - INFO - __main__ -     ********************\n","05/05/2023 16:03:07 - INFO - __main__ -     Best bleu:24.44\n","05/05/2023 16:03:07 - INFO - __main__ -     ********************\n","epoch 19 loss 1.6326: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:03:57 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:03:57 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:03:57 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:04:00 - INFO - __main__ -     eval_ppl = 28.13155\n","05/05/2023 16:04:00 - INFO - __main__ -     global_step = 881\n","05/05/2023 16:04:00 - INFO - __main__ -     train_loss = 1.6326\n","05/05/2023 16:04:00 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:08:34 - INFO - __main__ -     bleu-4 = 24.17 \n","05/05/2023 16:08:34 - INFO - __main__ -     ********************\n","epoch 20 loss 1.5585: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:09:22 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:09:22 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:09:22 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:09:25 - INFO - __main__ -     eval_ppl = 28.29549\n","05/05/2023 16:09:25 - INFO - __main__ -     global_step = 925\n","05/05/2023 16:09:25 - INFO - __main__ -     train_loss = 1.5585\n","05/05/2023 16:09:25 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:14:17 - INFO - __main__ -     bleu-4 = 22.55 \n","05/05/2023 16:14:17 - INFO - __main__ -     ********************\n","epoch 21 loss 1.4825: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:15:04 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:15:04 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:15:04 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:15:08 - INFO - __main__ -     eval_ppl = 28.77495\n","05/05/2023 16:15:08 - INFO - __main__ -     global_step = 969\n","05/05/2023 16:15:08 - INFO - __main__ -     train_loss = 1.4825\n","05/05/2023 16:15:08 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:19:54 - INFO - __main__ -     bleu-4 = 25.88 \n","05/05/2023 16:19:54 - INFO - __main__ -     ********************\n","05/05/2023 16:19:54 - INFO - __main__ -     Best bleu:25.88\n","05/05/2023 16:19:54 - INFO - __main__ -     ********************\n","epoch 22 loss 1.416: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:20:43 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:20:43 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:20:43 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:20:46 - INFO - __main__ -     eval_ppl = 28.35253\n","05/05/2023 16:20:46 - INFO - __main__ -     global_step = 1013\n","05/05/2023 16:20:46 - INFO - __main__ -     train_loss = 1.416\n","05/05/2023 16:20:46 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:25:26 - INFO - __main__ -     bleu-4 = 25.68 \n","05/05/2023 16:25:26 - INFO - __main__ -     ********************\n","epoch 23 loss 1.3374: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:26:13 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:26:13 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:26:13 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:26:17 - INFO - __main__ -     eval_ppl = 29.27726\n","05/05/2023 16:26:17 - INFO - __main__ -     global_step = 1057\n","05/05/2023 16:26:17 - INFO - __main__ -     train_loss = 1.3374\n","05/05/2023 16:26:17 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:30:47 - INFO - __main__ -     bleu-4 = 24.76 \n","05/05/2023 16:30:47 - INFO - __main__ -     ********************\n","epoch 24 loss 1.2899: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:31:35 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:31:35 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:31:35 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:31:38 - INFO - __main__ -     eval_ppl = 28.31927\n","05/05/2023 16:31:38 - INFO - __main__ -     global_step = 1101\n","05/05/2023 16:31:38 - INFO - __main__ -     train_loss = 1.2899\n","05/05/2023 16:31:38 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:36:35 - INFO - __main__ -     bleu-4 = 26.57 \n","05/05/2023 16:36:35 - INFO - __main__ -     ********************\n","05/05/2023 16:36:35 - INFO - __main__ -     Best bleu:26.57\n","05/05/2023 16:36:35 - INFO - __main__ -     ********************\n","epoch 25 loss 1.2266: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:37:25 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:37:25 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:37:25 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:37:28 - INFO - __main__ -     eval_ppl = 28.76547\n","05/05/2023 16:37:28 - INFO - __main__ -     global_step = 1145\n","05/05/2023 16:37:28 - INFO - __main__ -     train_loss = 1.2266\n","05/05/2023 16:37:28 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:41:54 - INFO - __main__ -     bleu-4 = 26.07 \n","05/05/2023 16:41:54 - INFO - __main__ -     ********************\n","epoch 26 loss 1.1674: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 16:42:41 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:42:41 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:42:41 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:42:45 - INFO - __main__ -     eval_ppl = 29.25801\n","05/05/2023 16:42:45 - INFO - __main__ -     global_step = 1189\n","05/05/2023 16:42:45 - INFO - __main__ -     train_loss = 1.1674\n","05/05/2023 16:42:45 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:47:27 - INFO - __main__ -     bleu-4 = 24.87 \n","05/05/2023 16:47:27 - INFO - __main__ -     ********************\n","epoch 27 loss 1.1183: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 16:48:14 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:48:14 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:48:14 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:48:18 - INFO - __main__ -     eval_ppl = 29.47462\n","05/05/2023 16:48:18 - INFO - __main__ -     global_step = 1233\n","05/05/2023 16:48:18 - INFO - __main__ -     train_loss = 1.1183\n","05/05/2023 16:48:18 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:52:47 - INFO - __main__ -     bleu-4 = 26.26 \n","05/05/2023 16:52:47 - INFO - __main__ -     ********************\n","epoch 28 loss 1.0777: 100% 44/44 [00:48<00:00,  1.09s/it]\n","05/05/2023 16:53:35 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:53:35 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:53:35 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:53:39 - INFO - __main__ -     eval_ppl = 29.75241\n","05/05/2023 16:53:39 - INFO - __main__ -     global_step = 1277\n","05/05/2023 16:53:39 - INFO - __main__ -     train_loss = 1.0777\n","05/05/2023 16:53:39 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 16:58:09 - INFO - __main__ -     bleu-4 = 27.0 \n","05/05/2023 16:58:09 - INFO - __main__ -     ********************\n","05/05/2023 16:58:09 - INFO - __main__ -     Best bleu:27.0\n","05/05/2023 16:58:09 - INFO - __main__ -     ********************\n","epoch 29 loss 1.0289: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 16:59:01 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 16:59:01 - INFO - __main__ -     Num examples = 150\n","05/05/2023 16:59:01 - INFO - __main__ -     Batch size = 16\n","05/05/2023 16:59:04 - INFO - __main__ -     eval_ppl = 30.01662\n","05/05/2023 16:59:04 - INFO - __main__ -     global_step = 1321\n","05/05/2023 16:59:04 - INFO - __main__ -     train_loss = 1.0289\n","05/05/2023 16:59:04 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:03:45 - INFO - __main__ -     bleu-4 = 26.58 \n","05/05/2023 17:03:45 - INFO - __main__ -     ********************\n","epoch 30 loss 0.9819: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:04:33 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:04:33 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:04:33 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:04:36 - INFO - __main__ -     eval_ppl = 30.37293\n","05/05/2023 17:04:36 - INFO - __main__ -     global_step = 1365\n","05/05/2023 17:04:36 - INFO - __main__ -     train_loss = 0.9819\n","05/05/2023 17:04:36 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:09:20 - INFO - __main__ -     bleu-4 = 27.28 \n","05/05/2023 17:09:20 - INFO - __main__ -     ********************\n","05/05/2023 17:09:20 - INFO - __main__ -     Best bleu:27.28\n","05/05/2023 17:09:20 - INFO - __main__ -     ********************\n","epoch 31 loss 0.9418: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:10:10 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:10:10 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:10:10 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:10:13 - INFO - __main__ -     eval_ppl = 30.65435\n","05/05/2023 17:10:13 - INFO - __main__ -     global_step = 1409\n","05/05/2023 17:10:13 - INFO - __main__ -     train_loss = 0.9418\n","05/05/2023 17:10:13 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:14:54 - INFO - __main__ -     bleu-4 = 27.16 \n","05/05/2023 17:14:54 - INFO - __main__ -     ********************\n","epoch 32 loss 0.8969: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 17:15:42 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:15:42 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:15:42 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:15:45 - INFO - __main__ -     eval_ppl = 30.82401\n","05/05/2023 17:15:45 - INFO - __main__ -     global_step = 1453\n","05/05/2023 17:15:45 - INFO - __main__ -     train_loss = 0.8969\n","05/05/2023 17:15:45 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:20:23 - INFO - __main__ -     bleu-4 = 26.63 \n","05/05/2023 17:20:23 - INFO - __main__ -     ********************\n","epoch 33 loss 0.8717: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:21:10 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:21:10 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:21:10 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:21:14 - INFO - __main__ -     eval_ppl = 31.5913\n","05/05/2023 17:21:14 - INFO - __main__ -     global_step = 1497\n","05/05/2023 17:21:14 - INFO - __main__ -     train_loss = 0.8717\n","05/05/2023 17:21:14 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:25:51 - INFO - __main__ -     bleu-4 = 27.27 \n","05/05/2023 17:25:51 - INFO - __main__ -     ********************\n","epoch 34 loss 0.8361: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:26:39 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:26:39 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:26:39 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:26:42 - INFO - __main__ -     eval_ppl = 31.72614\n","05/05/2023 17:26:42 - INFO - __main__ -     global_step = 1541\n","05/05/2023 17:26:42 - INFO - __main__ -     train_loss = 0.8361\n","05/05/2023 17:26:42 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:31:24 - INFO - __main__ -     bleu-4 = 26.98 \n","05/05/2023 17:31:24 - INFO - __main__ -     ********************\n","epoch 35 loss 0.8091: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:32:12 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:32:12 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:32:12 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:32:15 - INFO - __main__ -     eval_ppl = 32.05297\n","05/05/2023 17:32:15 - INFO - __main__ -     global_step = 1585\n","05/05/2023 17:32:15 - INFO - __main__ -     train_loss = 0.8091\n","05/05/2023 17:32:15 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:36:48 - INFO - __main__ -     bleu-4 = 27.57 \n","05/05/2023 17:36:48 - INFO - __main__ -     ********************\n","05/05/2023 17:36:48 - INFO - __main__ -     Best bleu:27.57\n","05/05/2023 17:36:48 - INFO - __main__ -     ********************\n","epoch 36 loss 0.7789: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:37:38 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:37:38 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:37:38 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:37:41 - INFO - __main__ -     eval_ppl = 31.92006\n","05/05/2023 17:37:41 - INFO - __main__ -     global_step = 1629\n","05/05/2023 17:37:41 - INFO - __main__ -     train_loss = 0.7789\n","05/05/2023 17:37:41 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:42:32 - INFO - __main__ -     bleu-4 = 27.37 \n","05/05/2023 17:42:32 - INFO - __main__ -     ********************\n","epoch 37 loss 0.754: 100% 44/44 [00:47<00:00,  1.08s/it]\n","05/05/2023 17:43:19 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:43:19 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:43:19 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:43:23 - INFO - __main__ -     eval_ppl = 32.17749\n","05/05/2023 17:43:23 - INFO - __main__ -     global_step = 1673\n","05/05/2023 17:43:23 - INFO - __main__ -     train_loss = 0.754\n","05/05/2023 17:43:23 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:48:01 - INFO - __main__ -     bleu-4 = 27.65 \n","05/05/2023 17:48:01 - INFO - __main__ -     ********************\n","05/05/2023 17:48:01 - INFO - __main__ -     Best bleu:27.65\n","05/05/2023 17:48:01 - INFO - __main__ -     ********************\n","epoch 38 loss 0.7282: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:48:51 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:48:51 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:48:51 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:48:54 - INFO - __main__ -     eval_ppl = 32.67686\n","05/05/2023 17:48:54 - INFO - __main__ -     global_step = 1717\n","05/05/2023 17:48:54 - INFO - __main__ -     train_loss = 0.7282\n","05/05/2023 17:48:54 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:53:36 - INFO - __main__ -     bleu-4 = 27.42 \n","05/05/2023 17:53:36 - INFO - __main__ -     ********************\n","epoch 39 loss 0.7058: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:54:23 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:54:23 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:54:23 - INFO - __main__ -     Batch size = 16\n","05/05/2023 17:54:27 - INFO - __main__ -     eval_ppl = 33.07014\n","05/05/2023 17:54:27 - INFO - __main__ -     global_step = 1761\n","05/05/2023 17:54:27 - INFO - __main__ -     train_loss = 0.7058\n","05/05/2023 17:54:27 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 17:59:10 - INFO - __main__ -     bleu-4 = 27.02 \n","05/05/2023 17:59:10 - INFO - __main__ -     ********************\n","epoch 40 loss 0.6865: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 17:59:58 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 17:59:58 - INFO - __main__ -     Num examples = 150\n","05/05/2023 17:59:58 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:00:01 - INFO - __main__ -     eval_ppl = 33.42108\n","05/05/2023 18:00:01 - INFO - __main__ -     global_step = 1805\n","05/05/2023 18:00:01 - INFO - __main__ -     train_loss = 0.6865\n","05/05/2023 18:00:01 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:04:38 - INFO - __main__ -     bleu-4 = 27.71 \n","05/05/2023 18:04:38 - INFO - __main__ -     ********************\n","05/05/2023 18:04:38 - INFO - __main__ -     Best bleu:27.71\n","05/05/2023 18:04:38 - INFO - __main__ -     ********************\n","epoch 41 loss 0.6707: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:05:30 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:05:30 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:05:30 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:05:33 - INFO - __main__ -     eval_ppl = 33.5683\n","05/05/2023 18:05:33 - INFO - __main__ -     global_step = 1849\n","05/05/2023 18:05:33 - INFO - __main__ -     train_loss = 0.6707\n","05/05/2023 18:05:33 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:10:04 - INFO - __main__ -     bleu-4 = 27.78 \n","05/05/2023 18:10:04 - INFO - __main__ -     ********************\n","05/05/2023 18:10:04 - INFO - __main__ -     Best bleu:27.78\n","05/05/2023 18:10:04 - INFO - __main__ -     ********************\n","epoch 42 loss 0.6559: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:10:54 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:10:54 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:10:54 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:10:58 - INFO - __main__ -     eval_ppl = 33.43843\n","05/05/2023 18:10:58 - INFO - __main__ -     global_step = 1893\n","05/05/2023 18:10:58 - INFO - __main__ -     train_loss = 0.6559\n","05/05/2023 18:10:58 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:15:36 - INFO - __main__ -     bleu-4 = 27.46 \n","05/05/2023 18:15:36 - INFO - __main__ -     ********************\n","epoch 43 loss 0.6427: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:16:23 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:16:23 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:16:23 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:16:27 - INFO - __main__ -     eval_ppl = 33.88032\n","05/05/2023 18:16:27 - INFO - __main__ -     global_step = 1937\n","05/05/2023 18:16:27 - INFO - __main__ -     train_loss = 0.6427\n","05/05/2023 18:16:27 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:21:08 - INFO - __main__ -     bleu-4 = 27.06 \n","05/05/2023 18:21:08 - INFO - __main__ -     ********************\n","epoch 44 loss 0.6274: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:21:56 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:21:56 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:21:56 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:22:00 - INFO - __main__ -     eval_ppl = 34.01439\n","05/05/2023 18:22:00 - INFO - __main__ -     global_step = 1981\n","05/05/2023 18:22:00 - INFO - __main__ -     train_loss = 0.6274\n","05/05/2023 18:22:00 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:26:39 - INFO - __main__ -     bleu-4 = 27.42 \n","05/05/2023 18:26:39 - INFO - __main__ -     ********************\n","epoch 45 loss 0.6203: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:27:27 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:27:27 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:27:27 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:27:31 - INFO - __main__ -     eval_ppl = 34.14154\n","05/05/2023 18:27:31 - INFO - __main__ -     global_step = 2025\n","05/05/2023 18:27:31 - INFO - __main__ -     train_loss = 0.6203\n","05/05/2023 18:27:31 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:32:11 - INFO - __main__ -     bleu-4 = 27.97 \n","05/05/2023 18:32:11 - INFO - __main__ -     ********************\n","05/05/2023 18:32:11 - INFO - __main__ -     Best bleu:27.97\n","05/05/2023 18:32:11 - INFO - __main__ -     ********************\n","epoch 46 loss 0.6091: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:33:02 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:33:02 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:33:02 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:33:05 - INFO - __main__ -     eval_ppl = 34.27092\n","05/05/2023 18:33:05 - INFO - __main__ -     global_step = 2069\n","05/05/2023 18:33:05 - INFO - __main__ -     train_loss = 0.6091\n","05/05/2023 18:33:05 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:37:40 - INFO - __main__ -     bleu-4 = 27.88 \n","05/05/2023 18:37:40 - INFO - __main__ -     ********************\n","epoch 47 loss 0.602: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:38:28 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:38:28 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:38:28 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:38:31 - INFO - __main__ -     eval_ppl = 34.47102\n","05/05/2023 18:38:31 - INFO - __main__ -     global_step = 2113\n","05/05/2023 18:38:31 - INFO - __main__ -     train_loss = 0.602\n","05/05/2023 18:38:31 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:43:16 - INFO - __main__ -     bleu-4 = 28.25 \n","05/05/2023 18:43:16 - INFO - __main__ -     ********************\n","05/05/2023 18:43:16 - INFO - __main__ -     Best bleu:28.25\n","05/05/2023 18:43:16 - INFO - __main__ -     ********************\n","epoch 48 loss 0.5944: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:44:06 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:44:06 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:44:06 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:44:09 - INFO - __main__ -     eval_ppl = 34.4783\n","05/05/2023 18:44:09 - INFO - __main__ -     global_step = 2157\n","05/05/2023 18:44:09 - INFO - __main__ -     train_loss = 0.5944\n","05/05/2023 18:44:09 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:48:49 - INFO - __main__ -     bleu-4 = 28.21 \n","05/05/2023 18:48:49 - INFO - __main__ -     ********************\n","epoch 49 loss 0.5903: 100% 44/44 [00:47<00:00,  1.09s/it]\n","05/05/2023 18:49:37 - INFO - __main__ -   \n","***** Running evaluation *****\n","05/05/2023 18:49:37 - INFO - __main__ -     Num examples = 150\n","05/05/2023 18:49:37 - INFO - __main__ -     Batch size = 16\n","05/05/2023 18:49:41 - INFO - __main__ -     eval_ppl = 34.44753\n","05/05/2023 18:49:41 - INFO - __main__ -     global_step = 2201\n","05/05/2023 18:49:41 - INFO - __main__ -     train_loss = 0.5903\n","05/05/2023 18:49:41 - INFO - __main__ -     ********************\n","Total: 150\n","05/05/2023 18:54:18 - INFO - __main__ -     bleu-4 = 28.09 \n","05/05/2023 18:54:18 - INFO - __main__ -     ********************\n"]}],"source":["!python run_tpu.py \\\n","  --do_train \\\n","  --do_eval \\\n","  --model_type $model_type \\\n","  --model_name_or_path $pretrained_model \\\n","  --train_filename $train_file \\\n","  --dev_filename $dev_file \\\n","  --output_dir $output_dir \\\n","  --max_source_length $source_length \\\n","  --max_target_length $target_length \\\n","  --beam_size $beam_size \\\n","  --train_batch_size $batch_size \\\n","  --eval_batch_size $batch_size \\\n","  --learning_rate $lr \\\n","  --weight_decay $decay \\\n","  --warmup_steps $warmup \\\n","  --num_train_epochs $epochs"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1683313129463,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"TSNkSBigYkqy"},"outputs":[],"source":["test_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n","test_file = f\"{data_dir}/{lang}/test.jsonl\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4091979,"status":"ok","timestamp":1683039430374,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"kHcDXqRGY5mT","outputId":"61dfd8e4-6bdf-404b-f8c5-a564763d3457"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-02 13:48:58.335694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/02/2023 13:49:00 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/python', load_model_path='model/python/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='../dataset/python/valid.jsonl', test_filename='../dataset/python/test.jsonl', config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=128, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n","05/02/2023 13:49:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n","05/02/2023 13:49:02 - INFO - __main__ -   reload model from model/python/checkpoint-best-bleu/pytorch_model.bin\n","05/02/2023 13:49:13 - INFO - __main__ -   Test file: ../dataset/python/valid.jsonl\n","100% 109/109 [32:31<00:00, 17.90s/it]\n","Total: 13914\n","05/02/2023 14:22:03 - INFO - __main__ -     bleu-4 = 17.45 \n","05/02/2023 14:22:03 - INFO - __main__ -     ********************\n","05/02/2023 14:22:03 - INFO - __main__ -   Test file: ../dataset/python/test.jsonl\n","100% 117/117 [34:36<00:00, 17.74s/it]\n","Total: 14918\n","05/02/2023 14:56:58 - INFO - __main__ -     bleu-4 = 17.91 \n","05/02/2023 14:56:58 - INFO - __main__ -     ********************\n"]}],"source":["!python run.py \\\n","  --do_test \\\n","  --model_type $model_type \\\n","  --model_name_or_path $pretrained_model \\\n","  --load_model_path $test_model \\\n","  --dev_filename $dev_file \\\n","  --test_filename $test_file \\\n","  --output_dir $output_dir \\\n","  --max_source_length $source_length \\\n","  --max_target_length $target_length \\\n","  --beam_size $beam_size \\\n","  --eval_batch_size $batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4959,"status":"ok","timestamp":1683039688307,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"WFeEFE6Dd6HV","outputId":"fcddef03-5014-4446-9b95-b945d39d8abb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total: 14918\n","17.91415264096644\n"]}],"source":["!python ../evaluator/evaluator.py model/$lang/test_1.gold < model/$lang/test_1.output"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10188,"status":"ok","timestamp":1683313142704,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"BPpAKxXw79hX","outputId":"24a52d0d-021c-4691-c6b7-9ec076d374bf"},"outputs":[{"data":{"text/plain":["Seq2Seq(\n","  (encoder): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (layers): ModuleList(\n","      (0-5): 6 x TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (multihead_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n","        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","        (dropout3): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (dense): Linear(in_features=768, out_features=768, bias=True)\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n","  (lsm): LogSoftmax(dim=-1)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","import torch.nn as nn\n","\n","from transformers import AutoTokenizer\n","from model import Seq2Seq\n","from transformers import RobertaConfig, RobertaModel\n","\n","tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n","\n","config = RobertaConfig.from_pretrained(pretrained_model)\n","encoder = RobertaModel.from_pretrained(pretrained_model, config = config)    \n","decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n","decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n","model = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n","                beam_size=beam_size,max_length=target_length,\n","                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n","model.load_state_dict(torch.load(test_model))\n","model.to('cuda')"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1683313143117,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"52S60aeUC32q"},"outputs":[],"source":["import pandas as pd\n","import json\n","\n","def jsonl_to_dataframe(jsonl_file):\n","    data = []\n","\n","    with open(jsonl_file, 'r') as file:\n","        for line in file:\n","            json_data = json.loads(line)\n","            code = ' '.join(json_data['code_tokens']).replace('\\n',' ')\n","            code = ' '.join(code.strip().split())\n","            docstring = ' '.join(json_data['docstring_tokens']).replace('\\n','')\n","            docstring = ' '.join(docstring.strip().split())   \n","            data.append({'code': code, 'docstring': docstring})\n","\n","    df = pd.DataFrame(data, columns=['code', 'docstring'])\n","    return df"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1683313145499,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"sLBvAM7BDqw7","outputId":"a4f3c0c5-623f-4604-dc0f-2eb0cf9810dc"},"outputs":[{"data":{"text/plain":["(700, 150, 150)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df_train = jsonl_to_dataframe(train_file)\n","df_dev = jsonl_to_dataframe(dev_file)\n","df_test = jsonl_to_dataframe(test_file)\n","\n","len(df_train), len(df_dev), len(df_test)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683313146644,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"obyn5l0OCj8Q","outputId":"5c720d6c-ae3e-42f1-d0c3-523777f9bff5"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-10aec2e1-2234-4104-803a-8fd545cfa87a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>code</th>\n","      <th>docstring</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td># ! /usr/bin/env python2 # Used to generate so...</td>\n","      <td>This code snippet generates icons of various s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>import torch from torch.autograd import Functi...</td>\n","      <td>This code snippet implements a truncated expon...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>import argparse from ast import arg from recbo...</td>\n","      <td>This code snippet runs a RecBole model on a gi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>import bpy import os , sys , subprocess class ...</td>\n","      <td>`` `` '' This code snippet creates an operator...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>import re import html xmlbody = `` '' '' &lt; ? x...</td>\n","      <td>`` `` '' This code snippet generates an OPML f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10aec2e1-2234-4104-803a-8fd545cfa87a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-10aec2e1-2234-4104-803a-8fd545cfa87a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-10aec2e1-2234-4104-803a-8fd545cfa87a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                code  \\\n","0  # ! /usr/bin/env python2 # Used to generate so...   \n","1  import torch from torch.autograd import Functi...   \n","2  import argparse from ast import arg from recbo...   \n","3  import bpy import os , sys , subprocess class ...   \n","4  import re import html xmlbody = `` '' '' < ? x...   \n","\n","                                           docstring  \n","0  This code snippet generates icons of various s...  \n","1  This code snippet implements a truncated expon...  \n","2  This code snippet runs a RecBole model on a gi...  \n","3  `` `` '' This code snippet creates an operator...  \n","4  `` `` '' This code snippet generates an OPML f...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head(5)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":3291,"status":"ok","timestamp":1683313153498,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"QMs-I-QbC2nb"},"outputs":[],"source":["from run import convert_examples_to_features, Example\n","from tqdm.auto import tqdm\n","\n","class Args:\n","    max_source_length = source_length\n","    max_target_length = target_length\n","\n","args = Args()\n","\n","def get_preds(df: pd.DataFrame):\n","    ps = []\n","    for idx, row in tqdm(df.iterrows(), total=len(df)):\n","        examples = [\n","            Example(idx, source = row.code, target = row.docstring)\n","        ]\n","        eval_features = convert_examples_to_features(\n","            examples, tokenizer, args, stage='test'\n","        )\n","        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n","        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n","\n","        with torch.no_grad():\n","            preds = model(source_ids = source_ids, source_mask = source_mask)  \n","            for pred in preds:\n","                t = pred[0].cpu().numpy()\n","                t = list(t)\n","                if 0 in t:\n","                    t = t[:t.index(0)]\n","                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n","                ps.append(text)\n","    \n","    return ps"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":694,"referenced_widgets":["09eb14ebfcdd4411b234a1d65ecda1b4","8e7ab8506a3948388688493f5e57547e","5364390ba7f9446eb217992cbdc7a392","f47eea2b2ac54a878aa3450f76628b64","f6f645c49a18462f8655b8a98a5b0340","1274c028311b4f6f82f64c724126cdd2","788b2cacbb7a4bc0a718243ac000cc88","bcb9690091df4fe0b3fa4c2b43a877ad","361f48ef08ee413f8ce189a180e7497b","54fe541e220c4089908db297ff88d985","2bd434ed57cf443095b55ea5c71361e7"]},"executionInfo":{"elapsed":14160,"status":"ok","timestamp":1683313169514,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"NjAH1Q_FF5Lc","outputId":"d6f9f774-9979-42fe-84f9-0c6922dff9e3"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09eb14ebfcdd4411b234a1d65ecda1b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["CODE:\n"," # ! /usr/bin/env python2 # Used to generate some icons # Requires inkscape and imagemagick pacages import os , subprocess , colorsys from xml.etree import ElementTree as ET ICODIR = `` ./images/ '' # Directory with icons CICONS = `` ./images/controller-icons/ '' # Directory controller-icons RECOLORS = { # Defines set of hue shifts for controller-icons # `` 0 '' : 0.0 , # Green - original '' 1 '' : 0.3 , # Blue '' 2 '' : 0.7 , # Red '' 3 '' : 0.9 , # Yellow '' 4 '' : 0.2 , # Cyan '' 5 '' : 0.8 , # Orange '' 6 '' : 0.5 , # Purple } # Generate svg state icons for size in ( 24 , 256 ) : for state in ( 'alive ' , 'dead ' , 'error ' , 'unknown ' ) : print `` scc-statusicon- % s.png '' % ( state , ) subprocess.call ( [ '' inkscape '' , '' % s/scc-statusicon- % s.svg '' % ( ICODIR , state ) , '' -- export-area-page '' , '' -- export-png= % s/ % sx % s/status/scc- % s.png '' % ( ICODIR , size , size , state ) , '' -- export-width= % s '' % ( size , ) , '' -- export-height= % s '' % ( size , ) ] ) def html_to_rgb ( html ) : '' '' '' Converts # rrggbbaa or # rrggbb to r , g , b , a in ( 0,1 ) ranges `` '' '' html = html.strip ( `` # '' ) if len ( html ) == 6 : html = html + `` ff '' elif html == `` none '' : return 0 , 0 , 0 , 0 elif len ( html ) ! = 8 : raise ValueError ( `` Needs RRGGBB ( AA ) format , got ' % s ' '' % ( html , ) ) return tuple ( ( float ( int ( html [ i : i+2 ] ,16 ) ) / 255.0 for i in xrange ( 0 , len ( html ) , 2 ) ) ) def rgb_to_html ( r , g , b ) : '' '' '' Convets rgb back to html color code `` '' '' return `` # '' + `` '' .join ( ( `` % 02x '' % int ( x * 255 ) for x in ( r , g , b ) ) ) def recolor ( tree , add ) : '' '' '' Recursive part of recolor_strokes and recolor_background `` '' '' if 'id ' in tree.attrib and `` overlay '' in tree.attrib [ 'id ' ] : return for child in tree : if 'style ' in child.attrib : styles = { a : b for ( a , b ) in ( x.split ( `` : '' , 1 ) for x in child.attrib [ 'style ' ] .split ( ' ; ' ) if `` : '' in x ) } if `` fill '' in styles or `` stroke '' in styles : for key in ( `` fill '' , `` stroke '' ) : if key in styles : # Convert color to HSV r , g , b , a = html_to_rgb ( styles [ key ] ) h , s , v = colorsys.rgb_to_hsv ( r , g , b ) # Shift hue h += add while h > 1.0 : h -= 1.0 # Convert it back r , g , b = colorsys.hsv_to_rgb ( h , s , v ) # Store styles [ key ] = rgb_to_html ( r , g , b ) child.attrib [ `` style '' ] = `` ; '' .join ( ( `` : '' .join ( ( x , styles [ x ] ) ) for x in styles ) ) recolor ( child , add ) # Generate different colors for controller icons ET.register_namespace ( `` '' , '' http : //www.w3.org/2000/svg '' ) for tp in ( `` sc '' , `` scbt '' , `` fake '' , `` ds4 '' , `` hid '' , `` rpad '' ) : # Read svg and parse it data = file ( `` % s/ % s-0.svg '' % ( CICONS , tp ) , `` r '' ) .read ( ) # Create recolored images for key in RECOLORS : tree = ET.fromstring ( data ) # Walk recursively and recolor everything that has color recolor ( tree , RECOLORS [ key ] ) out = `` % s/ % s- % s.svg '' % ( CICONS , tp , key ) file ( out , `` w '' ) .write ( ET.tostring ( tree ) ) print out\n","DOCSTRING (reference):\n"," This code snippet generates icons of various sizes and colors for use in a controller-icons directory . It uses the inkscape and imagemagick packages to generate the icons from SVG files . It also defines a set of hue shifts for the controller-icons and uses the colorsys module to convert between HTML and RGB color formats . Finally , it uses an ElementTree to recursively recolor the icons and write the results to the controller-icons directory .\n","DOCSTRING (model):\n"," This code snippet generates icons for a controller , using Inkscape and Imagemagick packages . It uses set of hue shifts and rgb values to convert the html_to_to_html functions to convert the hue shifts and hue shifts . It uses the RECOLORS dictionary of hue shifts and rgb_to_rgb and rgb_to_to_to_to_to_to_html functions to recolor dictionary of images , and RGB values .\n","===========================================================================\n","CODE:\n"," import torch from torch.autograd import Function from torch.cuda.amp import custom_bwd , custom_fwd class _trunc_exp ( Function ) : @ staticmethod @ custom_fwd ( cast_inputs=torch.float32 ) def forward ( ctx , x ) : ctx.save_for_backward ( x ) return torch.exp ( x ) @ staticmethod @ custom_bwd def backward ( ctx , g ) : x = ctx.saved_tensors [ 0 ] return g * torch.exp ( x.clamp ( -15 , 15 ) ) trunc_exp = _trunc_exp.apply\n","DOCSTRING (reference):\n"," This code snippet implements a truncated exponential function using PyTorch . The forward pass uses the torch.exp ( ) function to calculate the exponential of the input tensor and the backward pass uses the torch.exp ( ) function with a clamp of -15 to 15 to calculate the gradient . The custom_fwd and custom_bwd decorators are used to enable mixed precision in the forward and backward passes . The _trunc_exp class is used to define the forward and backward passes , and the trunc_exp function is used to apply the _trunc_exp class to the input tensor .\n","DOCSTRING (model):\n"," This code snippet implements an encoder function for a convolutional neural network . It imports the necessary modules and defines a function , and then iterates through a function . The decoder function takes a convolutional layer as an argument and then iterates through the loss function .\n","===========================================================================\n","CODE:\n"," import argparse from ast import arg from recbole.quick_start import run_recbole , run_recboles from recbole.utils import list_to_latex def run ( args , model , config_file_list ) : if args.nproc == 1 and args.world_size < = 0 : res = run_recbole ( model=model , dataset=args.dataset , config_file_list=config_file_list , ) else : if args.world_size == -1 : args.world_size = args.nproc import torch.multiprocessing as mp res = mp.spawn ( run_recboles , args= ( args.model , args.dataset , config_file_list , args.ip , args.port , args.world_size , args.nproc , args.group_offset , ) , nprocs=args.nproc , ) return res if __name__ == `` __main__ '' : parser = argparse.ArgumentParser ( ) parser.add_argument ( `` -- model_list '' , `` -m '' , type=str , default= '' BPR '' , help= '' name of models '' ) parser.add_argument ( `` -- dataset '' , `` -d '' , type=str , default= '' ml-100k '' , help= '' name of datasets '' ) parser.add_argument ( `` -- config_files '' , type=str , default=None , help= '' config files '' ) parser.add_argument ( `` -- valid_latex '' , type=str , default= '' ./latex/valid.tex '' , help= '' config files '' ) parser.add_argument ( `` -- test_latex '' , type=str , default= '' ./latex/test.tex '' , help= '' config files '' ) parser.add_argument ( `` -- nproc '' , type=int , default=1 , help= '' the number of process in this group '' ) parser.add_argument ( `` -- ip '' , type=str , default= '' localhost '' , help= '' the ip of master node '' ) parser.add_argument ( `` -- port '' , type=str , default= '' 5678 '' , help= '' the port of master node '' ) parser.add_argument ( `` -- world_size '' , type=int , default=-1 , help= '' total number of jobs '' ) parser.add_argument ( `` -- group_offset '' , type=int , default=0 , help= '' the global rank offset of this group '' , ) args , _ = parser.parse_known_args ( ) model_list = args.model_list.strip ( ) .split ( `` , '' ) config_file_list = ( args.config_files.strip ( ) .split ( `` `` ) if args.config_files else None ) valid_file = args.valid_latex.strip ( ) test_file = args.test_latex.strip ( ) valid_result_list = [ ] test_result_list = [ ] run_times = len ( model_list ) for idx in range ( run_times ) : model = model_list [ idx ] valid_res_dict = { `` Model '' : model } test_res_dict = { `` Model '' : model } result = run ( args , model , config_file_list ) valid_res_dict.update ( result [ `` best_valid_result '' ] ) test_res_dict.update ( result [ `` test_result '' ] ) bigger_flag = result [ `` valid_score_bigger '' ] subset_columns = list ( result [ `` best_valid_result '' ] .keys ( ) ) valid_result_list.append ( valid_res_dict ) test_result_list.append ( test_res_dict ) df_valid , tex_valid = list_to_latex ( convert_list=valid_result_list , bigger_flag=bigger_flag , subset_columns=subset_columns , ) df_test , tex_test = list_to_latex ( convert_list=test_result_list , bigger_flag=bigger_flag , subset_columns=subset_columns , ) with open ( valid_file , `` w '' ) as f : f.write ( tex_valid ) with open ( test_file , `` w '' ) as f : f.write ( tex_test )\n","DOCSTRING (reference):\n"," This code snippet runs a RecBole model on a given dataset and saves the results in a LaTeX file . It takes in arguments such as the model list , dataset name , config files , valid and test LaTeX files , number of processes , IP address , port , world size , and group offset . It then runs the model and stores the results in a dictionary . Finally , it converts the dictionary into a LaTeX file and saves it .\n","DOCSTRING (model):\n"," `` `` '' This code snippet runs a TensorFlow model from two different models on a given dataset . It takes in two parameters , parses the model , and runs each model on a random seeds for each model . The results are then runs a random seeds for the two-test. `` '' ''\n","===========================================================================\n","CODE:\n"," import bpy import os , sys , subprocess class op ( bpy.types.Operator ) : bl_idname = `` uv.textools_texture_open '' bl_label = `` Open Texture '' bl_description = `` Open the texture on the system '' name : bpy.props.StringProperty ( name= '' image name '' , default = `` '' ) @ classmethod def poll ( cls , context ) : return True def execute ( self , context ) : open_texture ( self , context ) return { 'FINISHED ' } def open_texture ( self , context ) : if self.name in bpy.data.images : image = bpy.data.images [ self.name ] if image.filepath ! = `` '' : path = bpy.path.abspath ( image.filepath ) # https : //meshlogic.github.io/posts/blender/addons/extra-image-list/ # https : //docs.blender.org/api/blender_python_api_2_78_release/bpy.ops.image.html print ( `` Open : { } '' .format ( path ) ) if sys.platform == `` win32 '' : os.startfile ( path ) else : opener = '' open '' if sys.platform == `` darwin '' else `` xdg-open '' subprocess.call ( [ opener , path ] ) bpy.utils.register_class ( op )\n","DOCSTRING (reference):\n"," `` `` '' This code snippet creates an operator that opens a texture from the Blender data images . It checks the filepath of the image , then opens the texture using the appropriate system command depending on the platform ( Windows , macOS , or Linux ) . '' '' ''\n","DOCSTRING (model):\n"," `` `` '' This code snippet creates an operator class called 'op ' that is used to open a texture on the system . The 'open_texture ' function is used to open a texture filepath using the operator is used to execute the operator . '' '' ''\n","===========================================================================\n","CODE:\n"," import re import html xmlbody = `` '' '' < ? xml version= '' 1.0 '' encoding= '' UTF-8 '' ? > < ! -- Created by generate_opml.py , please do n't edit manually . -- > < opml version= '' 1.0 '' > < head > < title > Data science blogs < /title > < /head > < body > < outline text= '' Data science blogs '' title= '' Data science blogs '' > { items } < /outline > < /body > < /opml > `` '' '' xmlitem = ' < outline type= '' rss '' text= '' { title } '' title= '' { title } '' ' 'xmlUrl= '' { rssfeed } '' htmlUrl= '' { httpfeed } '' / > ' readme = open ( 'README.md ' ) .read ( ) blogs = re.findall ( '\\ * ( . * ? ) http ( [ s ] { 0,1 } ) \\ : \\/\\/ ( . * ? ) \\ [ \\ ( RSS\\ ) \\ ] \\ ( ( . * ? ) \\ ) ' , readme ) items = `` for blog in blogs : item = xmlitem.format ( title=html.escape ( blog [ 0 ] .strip ( ) ) , httpfeed='http { 0 } : // { 1 } '.format ( blog [ 1 ] .strip ( ) , blog [ 2 ] .strip ( ) ) , rssfeed=blog [ 3 ] .strip ( ) ) items += '\\t\\t\\t { } \\r\\n'.format ( item ) open ( 'data-science.opml ' , ' w ' ) .write ( xmlbody.format ( items=items [ 0 : -2 ] ) )\n","DOCSTRING (reference):\n"," `` `` '' This code snippet generates an OPML file from a README.md file . It parses the README.md file for blog titles , URLs , and RSS feeds , and then creates an OPML file with the blog titles , URLs , and RSS feeds as outline items . The OPML file is saved as 'data-science.opml ' . '' '' ''\n","DOCSTRING (model):\n"," `` `` '' This code snippet sets up a Python package called 'query ' using the setuptools library . It reads in the version number from the __init__.py file , reads the README.md file , and creates a list of data from the specified file . It also prints out the contents of the file . '' '' ''\n","===========================================================================\n"]}],"source":["preds = get_preds(df_test.head(5))\n","for idx, row in df_test.head(5).iterrows():\n","    print('CODE:\\n', row.code)\n","    print('DOCSTRING (reference):\\n', row.docstring)\n","    print('DOCSTRING (model):\\n', preds[idx])\n","    print('='*75)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1683313195468,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"Z92aS27ZDdxd"},"outputs":[],"source":["import io\n","import tokenize\n","\n","def get_code_tokens(code):\n","    tokens = []\n","    code_stream = io.StringIO(code)\n","    for token in tokenize.generate_tokens(code_stream.readline):\n","        if token.type not in (tokenize.INDENT, tokenize.DEDENT, tokenize.NEWLINE, tokenize.NL, tokenize.COMMENT, tokenize.ENDMARKER):\n","            tokens.append(token.string)\n","    return tokens"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["c5406a29f44742df92341c7a34ff5bf3","b6dc0c4a70f84d51bf4560cb619f3925","71f424bb74504e899f4c4104876934c8","534ce3c292604ed9b6cab2d8246b3865","f4c8efba63964a5687116cb823a343ff","f5b7c2d370944834b1a60cdd4430aac8","a74736d8c41d4352818dbf926eaa9de1","ffa2c96e1fa547d4934446763831476d","6cad69ffecab4f1b805a63db02754df2","cc83ce010cc941f9bf4b0971f7b9fa83","e3d4187123bf457b981f9b872e4855db"]},"executionInfo":{"elapsed":2472,"status":"ok","timestamp":1683313209709,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"QiWec9lgHry-","outputId":"c7e6e872-a89e-4fe5-d150-85534835c56c"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5406a29f44742df92341c7a34ff5bf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DOCSTRING (model):\n"," `` `` '' This code snippet creates a Python script for a neural network using PyTorch ' . It takes in a list of size , pickle file , and calculates the point for each point . It then calculates the number of the number of the object . '' '' ''\n"]}],"source":["# Define a sample string as code\n","sample_code = \"\"\"\n","def factorial(n):\n","    if n == 0:\n","        return 1\n","    else:\n","        return n * factorial(n-1)\n","\"\"\"\n","\n","sample_tokens = get_code_tokens(sample_code)\n","code=' '.join(sample_tokens).replace('\\n',' ')\n","code=' '.join(code.strip().split())\n","\n","# Create a pandas DataFrame with the code as the 'code' column\n","sample_df = pd.DataFrame([{'code': code, 'docstring': ''}])\n","\n","# Make predictions on the code\n","predictions = get_preds(sample_df)\n","print(\"DOCSTRING (model):\\n\", predictions[0])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["470fa504d982452e9aaab1a7c3e3b633","1c356792c3ec47c497334cc0e434f834","0c99e51ee7eb4154b19e736c061b72a1","dea3aa138fa946ef9d3f1e741a41b5bd","db4ce4dc2f074a08aedee1621f0f52dc","89dbfd3bd62a49a7a375a1e0544c11ed","a22d61e0ac584822b66c26c323ebac69","7af21f6d9f3742c0bdcdc0b78219e766","703af4aabdf54a4885e92b42fd1fd1a9","f2c7d21d01554858b22abe3b9e86ce09","0841292dd77140f1b9c7c645c44e189d"]},"executionInfo":{"elapsed":2265,"status":"ok","timestamp":1683313255021,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"TyTm2gOHL9IX","outputId":"09417b77-415e-459c-d1bf-df9f1b589432"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"470fa504d982452e9aaab1a7c3e3b633","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DOCSTRING (model):\n"," `` `` '' This code snippet creates a command line interface . It takes in a list of number of time , a string and a list of time . If the user is set to True , the network is set to False . '' '' ''\n"]}],"source":["# Define a sample string as code\n","sample_code = \"\"\"\n","def prime(number):\n","    if number < 2:\n","        return False\n","    for i in range(2, number):\n","        if number % i == 0:\n","            return False\n","    return True\n","\"\"\"\n","\n","sample_tokens = get_code_tokens(sample_code)\n","code=' '.join(sample_tokens).replace('\\n',' ')\n","code=' '.join(code.strip().split())\n","\n","# Create a pandas DataFrame with the code as the 'code' column\n","sample_df = pd.DataFrame([{'code': code, 'docstring': ''}])\n","\n","# Make predictions on the code\n","predictions = get_preds(sample_df)\n","print(\"DOCSTRING (model):\\n\", predictions[0])"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["f03e43d544124db9bcc6bfa722ea045c","0f788396c1c14f7e81ae41db926d2175","880b38f67d064d3e93cd544263926851","843e9a36b73546ef84551819950ace52","d5058794fef3461bb90f4ba94dd4d55b","7cb170f1911f499bb7047ab1f3e8ce3f","05b5fb6013894257849461613fdeb022","81e81eb49b10460eb16837d29564b55e","a86b52a78b3a434e9ae29b5a9b89f9c9","a10c129fa9c6428a9706bad72b38d21a","56482aa4afeb461da0d29f196f434311"]},"executionInfo":{"elapsed":995,"status":"ok","timestamp":1683313257817,"user":{"displayName":"Francesco Lonardo","userId":"15859490455667766654"},"user_tz":-120},"id":"rY1pjR22MLVc","outputId":"a8629616-6882-416e-b9c8-f00a73c97837"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f03e43d544124db9bcc6bfa722ea045c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DOCSTRING (model):\n"," `` `` ''\n"]}],"source":["# Define a sample string as code\n","sample_code = \"\"\"\n","import base64\n","\n","PAYLOAD = b\"cat /home/bobby/flag.txt\"\n","\n","encoded = base64.b64encode(PAYLOAD)\n","print(encoded)\n","\n","command = \"python3 -c '__import__(\\\"os\\\").system((__import__(\\\"base64\\\").b64decode(\\\"\" + encoded.decode() + \"\\\")))'\"\n","print(command)\n","\"\"\"\n","\n","sample_tokens = get_code_tokens(sample_code)\n","code=' '.join(sample_tokens).replace('\\n',' ')\n","code=' '.join(code.strip().split())\n","\n","# Create a pandas DataFrame with the code as the 'code' column\n","sample_df = pd.DataFrame([{'code': code, 'docstring': ''}])\n","\n","# Make predictions on the code\n","predictions = get_preds(sample_df)\n","print(\"DOCSTRING (model):\\n\", predictions[0])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM7JQldMqWdG5RNVxMq78P8","gpuType":"T4","machine_shape":"hm","mount_file_id":"1i0oaQS8d0zLH4SyotExy47PV9tOPaJ9E","provenance":[{"file_id":"1i0oaQS8d0zLH4SyotExy47PV9tOPaJ9E","timestamp":1683292778088}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05b5fb6013894257849461613fdeb022":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0841292dd77140f1b9c7c645c44e189d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09eb14ebfcdd4411b234a1d65ecda1b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e7ab8506a3948388688493f5e57547e","IPY_MODEL_5364390ba7f9446eb217992cbdc7a392","IPY_MODEL_f47eea2b2ac54a878aa3450f76628b64"],"layout":"IPY_MODEL_f6f645c49a18462f8655b8a98a5b0340"}},"0c99e51ee7eb4154b19e736c061b72a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7af21f6d9f3742c0bdcdc0b78219e766","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_703af4aabdf54a4885e92b42fd1fd1a9","value":1}},"0f788396c1c14f7e81ae41db926d2175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cb170f1911f499bb7047ab1f3e8ce3f","placeholder":"","style":"IPY_MODEL_05b5fb6013894257849461613fdeb022","value":"100%"}},"1274c028311b4f6f82f64c724126cdd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c356792c3ec47c497334cc0e434f834":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89dbfd3bd62a49a7a375a1e0544c11ed","placeholder":"","style":"IPY_MODEL_a22d61e0ac584822b66c26c323ebac69","value":"100%"}},"2bd434ed57cf443095b55ea5c71361e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"361f48ef08ee413f8ce189a180e7497b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"470fa504d982452e9aaab1a7c3e3b633":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c356792c3ec47c497334cc0e434f834","IPY_MODEL_0c99e51ee7eb4154b19e736c061b72a1","IPY_MODEL_dea3aa138fa946ef9d3f1e741a41b5bd"],"layout":"IPY_MODEL_db4ce4dc2f074a08aedee1621f0f52dc"}},"534ce3c292604ed9b6cab2d8246b3865":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc83ce010cc941f9bf4b0971f7b9fa83","placeholder":"","style":"IPY_MODEL_e3d4187123bf457b981f9b872e4855db","value":" 1/1 [00:02&lt;00:00,  2.17s/it]"}},"5364390ba7f9446eb217992cbdc7a392":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcb9690091df4fe0b3fa4c2b43a877ad","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_361f48ef08ee413f8ce189a180e7497b","value":5}},"54fe541e220c4089908db297ff88d985":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56482aa4afeb461da0d29f196f434311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cad69ffecab4f1b805a63db02754df2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"703af4aabdf54a4885e92b42fd1fd1a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71f424bb74504e899f4c4104876934c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffa2c96e1fa547d4934446763831476d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cad69ffecab4f1b805a63db02754df2","value":1}},"788b2cacbb7a4bc0a718243ac000cc88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7af21f6d9f3742c0bdcdc0b78219e766":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb170f1911f499bb7047ab1f3e8ce3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e81eb49b10460eb16837d29564b55e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"843e9a36b73546ef84551819950ace52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a10c129fa9c6428a9706bad72b38d21a","placeholder":"","style":"IPY_MODEL_56482aa4afeb461da0d29f196f434311","value":" 1/1 [00:00&lt;00:00,  1.16it/s]"}},"880b38f67d064d3e93cd544263926851":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e81eb49b10460eb16837d29564b55e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a86b52a78b3a434e9ae29b5a9b89f9c9","value":1}},"89dbfd3bd62a49a7a375a1e0544c11ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e7ab8506a3948388688493f5e57547e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1274c028311b4f6f82f64c724126cdd2","placeholder":"","style":"IPY_MODEL_788b2cacbb7a4bc0a718243ac000cc88","value":"100%"}},"a10c129fa9c6428a9706bad72b38d21a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22d61e0ac584822b66c26c323ebac69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a74736d8c41d4352818dbf926eaa9de1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a86b52a78b3a434e9ae29b5a9b89f9c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6dc0c4a70f84d51bf4560cb619f3925":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b7c2d370944834b1a60cdd4430aac8","placeholder":"","style":"IPY_MODEL_a74736d8c41d4352818dbf926eaa9de1","value":"100%"}},"bcb9690091df4fe0b3fa4c2b43a877ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5406a29f44742df92341c7a34ff5bf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6dc0c4a70f84d51bf4560cb619f3925","IPY_MODEL_71f424bb74504e899f4c4104876934c8","IPY_MODEL_534ce3c292604ed9b6cab2d8246b3865"],"layout":"IPY_MODEL_f4c8efba63964a5687116cb823a343ff"}},"cc83ce010cc941f9bf4b0971f7b9fa83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5058794fef3461bb90f4ba94dd4d55b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4ce4dc2f074a08aedee1621f0f52dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dea3aa138fa946ef9d3f1e741a41b5bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c7d21d01554858b22abe3b9e86ce09","placeholder":"","style":"IPY_MODEL_0841292dd77140f1b9c7c645c44e189d","value":" 1/1 [00:01&lt;00:00,  1.56s/it]"}},"e3d4187123bf457b981f9b872e4855db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f03e43d544124db9bcc6bfa722ea045c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f788396c1c14f7e81ae41db926d2175","IPY_MODEL_880b38f67d064d3e93cd544263926851","IPY_MODEL_843e9a36b73546ef84551819950ace52"],"layout":"IPY_MODEL_d5058794fef3461bb90f4ba94dd4d55b"}},"f2c7d21d01554858b22abe3b9e86ce09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47eea2b2ac54a878aa3450f76628b64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54fe541e220c4089908db297ff88d985","placeholder":"","style":"IPY_MODEL_2bd434ed57cf443095b55ea5c71361e7","value":" 5/5 [00:13&lt;00:00,  2.37s/it]"}},"f4c8efba63964a5687116cb823a343ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b7c2d370944834b1a60cdd4430aac8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f645c49a18462f8655b8a98a5b0340":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffa2c96e1fa547d4934446763831476d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
